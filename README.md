# ğŸ¯ AI Lead Scoring & Prioritization Agent

**Frontend-Backend Architecture with Google Gemini AI**

A complete lead scoring system with separated frontend and backend, powered by Google's Gemini AI.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERFACE                            â”‚
â”‚                   (Streamlit Frontend)                       â”‚
â”‚                  http://localhost:8501                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ HTTP POST Request
                     â”‚ (Lead Data)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND API                                â”‚
â”‚                  (FastAPI Server)                            â”‚
â”‚                  http://localhost:8000                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ API Call
                     â”‚ (Formatted Prompt)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GOOGLE GEMINI LLM                           â”‚
â”‚              (gemini-2.0-flash-exp)                          â”‚
â”‚           Latest Gemini Flash 2.0 Model                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ JSON Response
                     â–¼
              (Flow returns back)
```

---

## âœ¨ Features

### ğŸ¨ **Separated Architecture**
- **Frontend**: Streamlit web UI (port 8501)
- **Backend**: FastAPI REST API (port 8000)
- **LLM**: Google Gemini AI (cloud)

### ğŸ”„ **Request Flow**
1. User enters lead info in Streamlit
2. Frontend sends HTTP POST to Backend
3. Backend formats prompt and calls Gemini
4. Gemini analyzes and returns JSON
5. Backend processes response
6. Frontend displays results to user

### ğŸ“Š **Rich Features**
- Interactive web interface
- Batch CSV upload processing
- Real-time analytics dashboard
- Score distribution charts
- Priority breakdowns
- Export to CSV

---

## ğŸ“ Project Structure

```
CRM_SRS_HACKATHON/
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/                 # FRONTEND (Streamlit)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ streamlit_app.py        # Web UI application
â”‚
â”œâ”€â”€ ğŸ“‚ backend/                  # BACKEND (FastAPI + LLM)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ api.py                   # REST API server
â”‚   â””â”€â”€ core_scoring.py          # Gemini LLM integration
â”‚
â”œâ”€â”€ ğŸ“‚ .venv/                    # Virtual environment (gitignored)
â”‚
â”œâ”€â”€ ğŸ” .env                      # Environment variables
â”œâ”€â”€ ğŸ“„ .env.example              # Template for .env
â”œâ”€â”€ ğŸš« .gitignore                # Git ignore rules
â”œâ”€â”€ ğŸ“‹ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“Š lead_data.csv            # Sample dataset (100 leads)
â”‚
â”œâ”€â”€ ğŸš€ start_backend.bat        # Start backend server
â”œâ”€â”€ ğŸš€ start_frontend.bat       # Start frontend UI
â”œâ”€â”€ ğŸš€ start_all.ps1            # Start both (PowerShell)
â”‚
â”œâ”€â”€ ğŸ“– README.md                # This file
â”‚
â””â”€â”€ ğŸ“œ (legacy files)           # Old single-file versions
    â”œâ”€â”€ lead_scorer.py
    â”œâ”€â”€ gemini_lead_scorer.py
    â”œâ”€â”€ core_scoring.py
    â”œâ”€â”€ api.py
    â””â”€â”€ streamlit_app.py
```

---

## ğŸš€ Quick Start

### Option 1: Start Both Services (Recommended)

**Using PowerShell:**
```powershell
.\start_all.ps1
```

This will:
- âœ… Start backend API on http://localhost:8000
- âœ… Start frontend UI on http://localhost:8501
- âœ… Open both in separate windows

### Option 2: Start Manually

**Terminal 1 - Start Backend:**
```bash
cd backend
python api.py
```

**Terminal 2 - Start Frontend:**
```bash
cd frontend
streamlit run streamlit_app.py
```

---

## ğŸ“¦ Installation

### 1. Activate Virtual Environment

**.venv already created!**

**Windows (PowerShell):**
```powershell
.venv\Scripts\Activate.ps1
```

**Windows (Command Prompt):**
```cmd
.venv\Scripts\activate.bat
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

**Installed packages:**
- `pandas` - Data manipulation
- `google-generativeai` - Gemini API
- `fastapi` + `uvicorn` - Backend API
- `streamlit` - Frontend UI
- `plotly` - Interactive charts
- `requests` - HTTP communication
- `python-dotenv` - Environment management

### 3. Configure API Key

Edit `.env` file in project root:
```env
GEMINI_API_KEY=your-actual-api-key-here
```

**Get your key:** [Google AI Studio](https://makersuite.google.com/app/apikey)

---

## ğŸ® Usage Guide

### 1. Start the Application

**Method A: PowerShell Script (Easiest)**
```powershell
.\start_all.ps1
```

**Method B: Batch Files**
```cmd
# Terminal 1
start_backend.bat

# Terminal 2
start_frontend.bat
```

### 2. Access the Frontend

Open your browser to: **http://localhost:8501**

### 3. Using the Web UI

#### ğŸ“ **Score Single Lead**
1. Select "Score Single Lead" from sidebar
2. Enter role (e.g., "CTO")
3. Select company size
4. Enter message/inquiry
5. Click "Score Lead"
6. View score and justification

#### ğŸ“¦ **Batch Processing**
1. Select "Batch Processing"
2. Upload CSV file (columns: role, company_size, message)
3. Click "Process All Leads"
4. Download scored results

#### ğŸ“Š **Analytics Dashboard**
1. Select "Analytics Dashboard"
2. View score distribution
3. See priority breakdowns
4. Export all data

---

## ğŸ”Œ API Endpoints

### Backend API Documentation

Access at: **http://localhost:8000/docs**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information |
| `/health` | GET | Health check (Gemini status) |
| `/score` | POST | Score single lead |
| `/score/batch` | POST | Score multiple leads |

### Example API Request

**Using curl:**
```bash
curl -X POST "http://localhost:8000/score" \
  -H "Content-Type: application/json" \
  -d '{
    "role": "CTO",
    "company_size": "500-1000",
    "message": "Urgent migration deadline. Need enterprise plan for 300+ users."
  }'
```

**Response:**
```json
{
  "score": 95,
  "justification": "Urgent migration, enterprise scale, C-suite authority",
  "priority_label": "ğŸ”¥ High Priority",
  "success": true,
  "error": null,
  "timestamp": "2025-11-07T21:59:00.000Z"
}
```

**Using Python:**
```python
import requests

response = requests.post(
    "http://localhost:8000/score",
    json={
        "role": "CTO",
        "company_size": "500-1000",
        "message": "Urgent migration needed"
    }
)

result = response.json()
print(f"Score: {result['score']}")
```

---

## ğŸ“Š Lead Scoring Criteria

The Gemini LLM evaluates leads based on:

### ğŸ”¥ High Score (80-100) - Contact Immediately
- âœ… **Urgency**: "deadline", "ASAP", "migration", "urgent"
- âœ… **Budget**: "$50k", "budget allocated", specific amounts
- âœ… **Authority**: CTO, VP, Director, C-suite roles
- âœ… **Scale**: "500+ users", "enterprise", large numbers

### âš ï¸ Medium Score (40-79) - Potential Fit
- âš ï¸ Vague interest: "more info", "pricing", "demo"
- âš ï¸ No clear urgency or timeline
- âš ï¸ Mid-level roles

### â„ï¸ Low Score (1-39) - Poor Fit
- âŒ Students or academic projects
- âŒ Job seekers
- âŒ Very small companies (<10 employees)

### ğŸš« Junk (0) - Spam/Irrelevant
- ğŸš« Spam messages
- ğŸš« Irrelevant inquiries

---

## ğŸ› ï¸ Troubleshooting

### Issue: Frontend shows "Backend API: Offline"

**Solution:**
1. Make sure backend is running first
2. Start backend: `python backend/api.py`
3. Check terminal for errors
4. Verify port 8000 is available

### Issue: "GEMINI_API_KEY not found"

**Solution:**
1. Check `.env` file exists in project root (not in frontend/backend folders)
2. Verify `GEMINI_API_KEY=your-key` is set
3. No quotes needed around the key
4. Restart backend server

### Issue: Port Already in Use

**Backend (port 8000):**
```python
# Edit backend/api.py, line ~240
uvicorn.run("api:app", port=8001)  # Change port
```

**Frontend (port 8501):**
```bash
streamlit run frontend/streamlit_app.py --server.port 8502
```

### Issue: Import Errors

**Solution:**
```bash
# Make sure you're in project root
cd e:\CRM_SRS_HACKATHON

# Install dependencies
pip install -r requirements.txt --force-reinstall
```

### Issue: Slow Responses

**Cause:** Gemini API rate limits (free tier: ~60 requests/min)

**Solution:**
- Process smaller batches
- Add delays between requests
- Upgrade API tier if needed

---

## ğŸ” Testing the Architecture

### 1. Test Backend Independently

**Start backend:**
```bash
cd backend
python api.py
```

**Test health endpoint:**
```bash
curl http://localhost:8000/health
```

**Expected response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-11-07T...",
  "gemini_initialized": true
}
```

### 2. Test Frontend-Backend Communication

1. Start both services
2. Open Streamlit UI
3. Check sidebar for "âœ… Backend API: Connected"
4. Score a test lead
5. Check backend terminal for request logs

---

## ğŸ“ˆ Scaling to Production

### Security
- âœ… API key in environment variables
- âœ… `.env` in `.gitignore`
- âš ï¸ Add authentication to API endpoints
- âš ï¸ Configure CORS for specific origins
- âš ï¸ Add rate limiting

### Performance
```python
# Add caching
from functools import lru_cache

# Async processing
from fastapi import BackgroundTasks

# Database
import sqlalchemy
```

### Monitoring
```python
# Logging
import logging
logging.basicConfig(level=logging.INFO)

# Metrics
from prometheus_client import Counter
```

---

## ğŸ“ Development

### Adding New Features

**To modify scoring logic:**
1. Edit `backend/core_scoring.py`
2. Update `INSTRUCTION_PROMPT` constant
3. Restart backend

**To modify UI:**
1. Edit `frontend/streamlit_app.py`
2. Streamlit auto-reloads on save
3. Refresh browser

**To add API endpoints:**
1. Edit `backend/api.py`
2. Add new route with `@app.post()` or `@app.get()`
3. Update frontend to call new endpoint

---

## ğŸ“š Resources

- [Google Gemini API Docs](https://ai.google.dev/docs)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Requests Library](https://requests.readthedocs.io/)

---

## ğŸ¤ Support

For issues:
1. Check backend terminal for errors
2. Check frontend sidebar for connection status
3. Verify `.env` configuration
4. Test API endpoints directly
5. Check console logs in both terminals

---

## ğŸ“„ License

This project is provided as-is for educational and commercial use.

---

**Built with â¤ï¸ using:**
- ğŸ¨ **Frontend**: Streamlit
- ğŸ–¥ï¸ **Backend**: FastAPI
- ğŸ¤– **AI**: Google Gemini
- ğŸ”„ **Communication**: HTTP/REST

ğŸ¯ Happy Lead Scoring!
